= K8s.
v1.0, 2020-11-14
:example-caption!:
:sectnums:
:sectnumlevels: 7


== What is K8s

++++
<!--<iframe width="560" height="315" src="https://www.youtube.com/embed/X48VuDVv0do?start=139&end=321" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
++++

== Main K8s Components

++++
<!--<iframe width="560" height="315" src="https://www.youtube.com/embed/X48VuDVv0do?start=321&end=1350https://youtu.be/X48VuDVv0do?t=1349" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
++++

=== Nodes and Pods
- Node - physical or virtual machine.
- Smalles unit of k8s is pod. Pod is abstraction over container. Usually 1 application per Pod. Pods in k8s commuticates via virtual k8s network. Echa Pod gets its own internal IP address.

=== Service and Ingress
- Service - permanent IP address that can be attached to to each Pod.
- Lifecycle of Pod and Service NOT connected, if Pod dies the service and its ip address will stay, so you don't have to change that end point any more.
- Ingress. Application needs to be acced from outside and for this you would have to create an external service. External service is the service that opens the communication from external sources. The request goes to Ingress and then it does the forwarding then to the service.

[plantuml]
....
partition Node1 #LightSkyBlue {
    - Ingress
    partition my-app(pod) {
        - Service
    }
    partition DB(pod) {
        -Service
    }
}
....

=== ConfigMap and Secret
- ConfigMap is external configuration of your application(url of a database or some other services, db username and password is not secure place to keep in ConfigMap). if we change endpoint of the servcice we just adjust the ConfigMap
- Secret is just like ConfigMap, but the difference is that it is used to store secret data, credentials for example. The information is in base64 encoded format

=== Volumes
If DB container gets restarted the data would be gone. Volumes attaches a physical storage on a hard drive to Pod. That storage can be either on a local machine, meaning on the same server node where the pod is running or it could be on a remote storage, meaning outside of the k8s cluster, it could be a cloud storage or your own premise storage which is not part of k8s cluster.

=== Deployment and Stateful Set

== K8s Architecture

++++
<!--<iframe width="560" height="315" src="https://www.youtube.com/embed/X48VuDVv0do?start=1350&end=2088https://youtu.be/X48VuDVv0do?t=1349" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
++++

=== Two type of nodes
- Master
- Slave
----
- Each node has multiple Pods on it.
- Three processes must be installed on every node
----
    * container runtime
    *
----
- Worker Nodes do the actual work

----


[plantuml]
----
skinparam Legend {
	BackgroundColor transparent
	BorderColor transparent
}
legend
Each node has multiple Pods on it
Three processes must be installed on every node
|_ container runtime
|_ kubelet(1)
|_ kube proxy(3)
Worker Nodes do the actual work
end legend
----

----
(1) Kubelete - interacts with both - the container and node, Kubelet starts the pod with a container inside, and then assigning resources from that node to the container like cpu, ram and storage resources.
----
----
(2) Servlet is a sort of loadbalancer that basically caches the request directed to the pod or the application and the forwads it to the repective pod
----
----
(3) Kube proxy forwards the requests
----

[plantuml]
----
skinparam Legend {
	BackgroundColor transparent
	BorderColor transparent
}
legend
How do you interact with this cluster
|_How to:
  |_ schedule pod?
  |_ monitor?
  |_ re-schedule/re-start pod?
  |_ join a new Node?
end legend
----
All these managing processes are done by *Master Nodes*
[plantuml]
----
skinparam Legend {
	BackgroundColor transparent
	BorderColor transparent
}
legend
Master processes
|_Api server(cluster gateway)
|_Scheduler
|_Controller manager
|_etcd(key value store of a cluster state. it is a cluster brain)
  |_ Is the cluster healthy?
  |_ What resources are available?
  |_ Did the cluster state change?
end legend
----


[plantuml]
----
title API Server
SomeRequest -> APIServer
APIServer -> ValidateRequest
ValidateRequest -> "other processes"
"other processes" -> Pod
----

[plantuml]
----
title Schedule
"Schedule New Pod" -> "API Server"
"API Server" -> Scheduler
Scheduler -> "Where to put the Pod?"
"Where to put the Pod?" -> Kubelet

----

[plantuml]
----
title Controller manager
"Controller manager" -> Scheduler
Scheduler -> Kubelet
Kubelet -> Pod

----

=== Example cluster set-up

== Minikube and kubectl - Local Setup

=== Master
==== Install
[source]
----
hostnamectl set-hostname master.art.local
echo "192.168.56.10 master.art.local master" >> /etc/hosts
echo "192.168.56.11 node1.art.local node1" >> /etc/hosts
echo "192.168.56.12 node2.art.local node2" >> /etc/hosts
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="--node-ip=192.168.56.10 --flannel-iface=enp0s8" sh -
----
==== Debug
[source]
----
systemctl status k3s
journalctl -f --unit k3s
watch -n3 kubectl get nodes
----
==== Config file
[source]
----
cat /etc/rancher/k3s/k3s.yaml
chmod 644 /etc/rancher/k3s/k3s.yaml
----
==== Token
[source]
----
cat /var/lib/rancher/k3s/server/token
----
==== Uninstall
[source]
----
/usr/local/bin/k3s-uninstall.sh
----
=== Node
==== Install
[source]
----
hostnamectl set-hostname node1.art.local node1
echo "192.168.56.10 master.art.local master" >> /etc/hosts
echo "192.168.56.11 node1.art.local node1" >> /etc/hosts
echo "192.168.56.12 node2.art.local node2" >> /etc/hosts
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="--node-ip=192.168.56.11 --flannel-iface=enp0s8" K3S_URL="https://192.168.56.10:6443" K3S_TOKEN="K108ada0b700e91cf2201586cedb9e0f26b7a5a7923fb551affb7aca393e03630c5::server:8568fd7b7e57846f03294ea4f6a3de00" sh -
----
==== Debug
[source]
----
journalctl -f --unit k3s-agent
----
==== Uninstall
[source]
----
/usr/local/bin/k3s-agent-uninstall.sh
----
++++
<!--<iframe width="560" height="315" src="https://www.youtube.com/embed/X48VuDVv0do?start=2088&end=2693https://youtu.be/X48VuDVv0do?t=1349" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
++++

== Main Kubectl Commands - K8s CLI

++++
<!--<iframe width="560" height="315" src="https://www.youtube.com/embed/X48VuDVv0do?start=2693&end=https://youtu.be/X48VuDVv0do?t=1349" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
++++

[plantuml]
----
skinparam Legend {
	BackgroundColor transparent
	BorderColor transparent
    FontSize 17

}
skinparam classFontColor red
skinparam classFontSize 10
skinparam classFontName Aapex
legend
CRUD commands
|_Create deployment
  |_ kubectl create deployment [name]
|_Edit deployment
  |_ kubectl edit deployment [name]
|_Delete deployment
  |_kubectl delete deployment [name]
|_etcd(key value store of a cluster state. it is a cluster brain)
Status of different K8s components
|_ kubectl get
  |_ nodes
  |_ pod
  |_ services
  |_ replicaset
  |_ deployment
Debbuging pods
|_Log to console
  |_ kubectl logs [pod name]
|_ Get Interacitve terminal
  |_ kubectl exec -it [pod name] --bin/bash
end legend
----

[source]
----
kubectl create -h
kubectl create deployment nginx-depl --image=nginx
kubectl get deployment
kubectl get pod
kubectl get replicaset
----
[plantuml]
----
title Layers of abstration
"Deployemt" ->
----
